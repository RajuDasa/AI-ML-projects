{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transfer learning using the VGG16 model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZk7ylkuyDW7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUoTHKyQyibP",
    "outputId": "c077ca26-dba6-4d20-b439-980e3b89126d"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "#take samples instead of whole dataset\n",
    "train_ds, validation_ds, test_ds = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split = [\"train[:30%]\", \"train[30%:40%]\", \"train[40%:50%]\"],  #30%,10%,10%\n",
    "    as_supervised = True,\n",
    "    batch_size=BATCH_SIZE\n",
    "    )\n",
    "train_ds.cardinality(), validation_ds.cardinality(), test_ds.cardinality()  #7k,2k,2k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHAznQNyINUu"
   },
   "source": [
    "**Plot few images:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "f5U_iDjR1MW5",
    "outputId": "42d5e0a0-3669-41a2-dc55-a6b4ca9a0aed"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "for i, (img,lbl) in enumerate(train_ds.unbatch().take(6)):\n",
    "  plt.subplot(2,3, i+1)\n",
    "  plt.imshow(img)\n",
    "  plt.title(int(lbl))\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YY1WhcPp57oL"
   },
   "source": [
    "**Resize, augment, normalize:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caQJ9MPh4Xmh"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 150\n",
    "\n",
    "#resize\n",
    "resize = tf.keras.layers.Resizing(IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "#normalize - convert img from RGB to BGR, and zero-center each color channel\n",
    "normalize = tf.keras.applications.vgg16.preprocess_input\n",
    "\n",
    "train_augment = tf.keras.Sequential([\n",
    "    resize,\n",
    "    #augment\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1)\n",
    "])\n",
    "\n",
    "train_ds = train_ds.map(lambda x,y: (normalize(train_augment(x)),y))\n",
    "validation_ds = validation_ds.map(lambda x,y: (normalize(resize(x)) ,y))\n",
    "test_ds = test_ds.map(lambda x,y: (normalize(resize(x)) ,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nJeipEj_1rm"
   },
   "source": [
    "**Model architecture** (using pre-trained VGG16 model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "nJfpvzd3_fMO",
    "outputId": "9891afb4-9c68-41e2-9f8b-4e68dcf92c9b"
   },
   "outputs": [],
   "source": [
    "import keras.applications.vgg16 as vgg16\n",
    "import keras.layers as layers\n",
    "\n",
    "base_model = vgg16.VGG16(include_top=False, input_shape=(IMG_SIZE,IMG_SIZE,3), pooling=\"avg\")\n",
    "base_model.trainable = False  #freeze\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMk8l6zDEUjs",
    "outputId": "cda910e8-c7b6-4229-e630-24fa62aa3195"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_ds, validation_data=validation_ds, epochs=15, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03qKpS30Oj2z"
   },
   "source": [
    "**Plot accuracy and loss:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "id": "YcYvx3CuIU3W",
    "outputId": "1f0d5e4e-fc89-41bd-8397-f2f1c9b700d8"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uR7GTl5aRqm7"
   },
   "source": [
    "**Test and Evaluate:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4220571e",
    "outputId": "a5f4f666-b764-4aa9-c60a-5639c3c5c7ce"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "62871f2f",
    "outputId": "c584eb4c-6aa5-4d40-b62c-925174cc139b"
   },
   "outputs": [],
   "source": [
    "def predict_and_display_images(dataset, model, num_images=6):\n",
    "  \"\"\"Predicts categories and displays images with predictions and confidence.\"\"\"\n",
    "\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  for i, (img, label) in enumerate(dataset.unbatch().take(num_images)):\n",
    "    # Add a batch dimension for prediction\n",
    "    img_with_batch = tf.expand_dims(img, axis=0)\n",
    "    prediction = model.predict(img_with_batch)\n",
    "\n",
    "    plt.subplot(3, 2, i + 1)\n",
    "    #normalized, won't show actual images\n",
    "    display_img = img\n",
    "\n",
    "    plt.imshow(display_img.numpy().astype(\"uint8\"))\n",
    "\n",
    "    predicted_class = \"Dog\" if prediction[0][0] > 0.5 else \"Cat\"\n",
    "    confidence = prediction[0][0] if prediction[0][0] > 0.5 else 1 - prediction[0][0]\n",
    "\n",
    "    plt.title(f\"Predicted: {predicted_class}\\nConfidence: {confidence:.2f}\\nTrue: {'Dog' if label.numpy() else 'Cat'}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "predict_and_display_images(test_ds, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDCzO5ThRDuk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
