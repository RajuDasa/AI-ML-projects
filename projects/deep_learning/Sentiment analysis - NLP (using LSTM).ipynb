{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentiment analysis - NLP using LSTM:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epsB-O-9IqH6"
   },
   "source": [
    "Import, install and load dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNtXQweWOQTL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kw3kCA_3uIb4",
    "outputId": "a757b97f-5978-49be-8081-8595afe74774"
   },
   "outputs": [],
   "source": [
    "%pip install contractions clean-text spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5556f86e",
    "outputId": "eb40ac01-5887-4ab2-ac57-d0605fc072a8"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mam12q7YI0my"
   },
   "source": [
    "**Define preprocess logic:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6n164Nv5mXdu",
    "outputId": "a59b915a-41f3-4fc0-bfc8-3ebb275c2b95"
   },
   "outputs": [],
   "source": [
    "import contractions\n",
    "from cleantext import clean\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')  #for stop words\n",
    "\n",
    "#handle contractions, remove extra-spaces, clean etc\n",
    "def preprocess(doc):\n",
    "  text = doc.text # Extract text from the Doc object\n",
    "  txt = contractions.fix(text)\n",
    "\n",
    "  txt = clean(\n",
    "      txt,\n",
    "      lower=True,\n",
    "      no_emoji=True,\n",
    "      no_urls=True,\n",
    "      no_punct=True,\n",
    "      replace_with_url=\"\"\n",
    "  )\n",
    "\n",
    "  txt = re.sub(r'\\s+', ' ', txt)\n",
    "  txt = txt.strip()\n",
    "\n",
    "  txt = [token.text for token in nlp(txt) if not token.is_stop]\n",
    "  return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZwCsI2MbQvjR",
    "outputId": "9f8ae107-3e5d-42e8-fe3f-422f4350042b"
   },
   "outputs": [],
   "source": [
    "test_text = \" and the a an you; your, they. 'quote', ALL_CAPS, oughtn't it be? won't, can't causes but airline is beautifull â™¥, contact http://t.co/aQjn4HwNaC, test  space, ...  \"\n",
    "processed_test_text = [preprocess(doc) for doc in nlp.pipe([test_text])] # Pass a list containing the text to nlp.pipe and iterate\n",
    "print(processed_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2KwNeYBIcJ5"
   },
   "source": [
    "**Load data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FRzPs6WAYaZu",
    "outputId": "5ea6f0f1-8a57-4fe6-834b-2bbc628c8762"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/Tweets.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "vjcbEi9FA04C",
    "outputId": "b117763c-8ca4-4592-d44d-459c68676986"
   },
   "outputs": [],
   "source": [
    "df['airline_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1jre2kCIM0R"
   },
   "source": [
    "**Select and format fields:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bdBWlvJB1Dz"
   },
   "outputs": [],
   "source": [
    "#Take relevant columns: 'airline_sentiment' and 'text'. Fix target field with numbers\n",
    "ddf = df[['airline_sentiment', 'text']]\n",
    "ddf.loc[:, 'airline_sentiment'] = ddf['airline_sentiment'].apply(lambda x: 0 if x==\"negative\" else 1 if x==\"neutral\" else 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEAsdqCfIVBB"
   },
   "source": [
    "**Preprocess textual data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae0ed0a4",
    "outputId": "5fbfb235-6807-4228-c8e1-7d48d3a7aac4"
   },
   "outputs": [],
   "source": [
    "text_processed = [preprocess(doc) for doc in nlp.pipe(ddf['text'])]\n",
    "text_processed[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBDLMWUhHvng"
   },
   "source": [
    "**Tokenize text to numbers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03364054"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "# max_words = len(set([word for sublist in text_processed for word in sublist])) + 1 # Add 1 for padding token\n",
    "# max from top freq. words to consider for vocab, remaining words become OOV\n",
    "max_words = 10000\n",
    "\n",
    "# Determine the maximum sequence length. Pad/truncate min/max sentences\n",
    "max_len = max([len(seq) for seq in text_processed])\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=max_words,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_len)\n",
    "\n",
    "#build vocabulary - key method\n",
    "vectorize_layer.adapt([' '.join(x) for x in text_processed])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWSNiSXONwVs"
   },
   "source": [
    "**Split data for validation set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcVi8joPA7mS"
   },
   "outputs": [],
   "source": [
    "percent = round(len(ddf) * 0.2)\n",
    "x_val = text_processed[-percent:]\n",
    "y_val = ddf['airline_sentiment'][-percent:]\n",
    "x_train = text_processed[:-percent]\n",
    "y_train = ddf['airline_sentiment'][:-percent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfPaHapQS0tL"
   },
   "source": [
    "**model architecture:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8bFnc61S35F",
    "outputId": "e2e1d069-43b0-44f6-f0da-34d85ed205b9"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "embedding_dim = 128\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=max_len))\n",
    "model.add(SpatialDropout1D(0.25))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u7IzPjpvUHyU",
    "outputId": "c2770fc4-b381-420e-fc2d-6f898c7372a2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Apply the vectorize_layer to the training and validation data\n",
    "x_train_vectorized = vectorize_layer([' '.join(x) for x in x_train])\n",
    "x_val_vectorized = vectorize_layer([' '.join(x) for x in x_val])\n",
    "\n",
    "# Convert y_train and y_val to NumPy arrays of integers\n",
    "y_train_numeric = np.array(y_train).astype(int)\n",
    "y_val_numeric = np.array(y_val).astype(int)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(x_train_vectorized, y_train_numeric, batch_size=64, epochs=10, validation_data=(x_val_vectorized, y_val_numeric))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GflkUIaiOti"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
